
import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer, KNNImputer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from pathlib import Path # Importa Path
from schemas.column import Column

def fit_transform_with_column_names(transformer, X: pd.DataFrame):
    # Ajustamos y transformamos los datos
    X_transformed = transformer.fit_transform(X)

    # Obtenemos las columnas procesadas y las que pasaron por passthrough
    new_feature_names = transformer.get_feature_names_out()

    # Reparar nombres: eliminar prefijos del transformer
    clean_names = [
        name.split("__")[1] if "__" in name else name
        for name in new_feature_names
    ]

    # Convertimos a DataFrame con los nombres originales
    return pd.DataFrame(X_transformed, columns=clean_names, index=X.index)

# --- Funci√≥n auxiliar para convertir tipos (reutilizable) ---
def ensure_numeric_types(df: pd.DataFrame, columns: list) -> pd.DataFrame:
    """
    Intenta convertir las columnas especificadas a un tipo num√©rico (int o float).
    Si una columna puede ser representada como entero sin perder informaci√≥n (y puede contener NaN),
    se convertir√° a Int64 (el tipo entero de Pandas que soporta NaN).
    De lo contrario, se convertir√° a float64.
    Los valores que no puedan convertirse a n√∫mero se reemplazar√°n con NaN.

    Args:
        df (pd.DataFrame): El DataFrame de entrada.
        columns (list): Lista de nombres de columnas a convertir.

    Returns:
        pd.DataFrame: El DataFrame con las columnas convertidas. Retorna una copia para evitar side effects.
    """
    df_copy = df.copy() # Trabajar siempre en una copia

    print("\n--- Asegurando Tipos Num√©ricos ---")

    for col in columns:
        if col not in df_copy.columns:
            print(f"  Advertencia: La columna '{col}' no se encontr√≥ en el DataFrame. Saltando conversi√≥n.")
            continue

        original_dtype = df_copy[col].dtype

        try:
            # Primero, intenta convertir a num√©rico, forzando errores a NaN
            # Esto es clave para limpiar cualquier string o valor no convertible
            temp_series = pd.to_numeric(df_copy[col], errors='coerce')

            # --- L√≥gica para decidir entre Int64 y float64 ---
            # 1. Verificar si hay NaNs despu√©s de la conversi√≥n.
            # 2. Si no hay NaNs y todos los valores son enteros (sin parte decimal),
            #    entonces podemos intentar convertir a 'Int64' (el tipo entero de Pandas que maneja NaNs).
            #    Si hay decimales o NaNs, generalmente float es m√°s seguro.

            # Identificar si todos los valores no nulos son "enteros" (sin parte fraccional)
            # Y si la columna no estaba ya como un tipo flotante que introdujo decimales
            is_pure_integer = (temp_series.dropna() == temp_series.dropna().astype(int)).all()

            if temp_series.isnull().any() or not is_pure_integer:
                # Si hay NaNs (incluyendo los 'coerce') O si hay valores no enteros (decimales),
                # la convertimos a float64. Float64 es el tipo seguro para decimales y NaNs.
                df_copy[col] = temp_series.astype(float)
                print(f"  Columna '{col}': Convertida de {original_dtype} a {df_copy[col].dtype} (contiene decimales o NaNs, o no es puramente entera).")
            else:
                # Si no hay NaNs y todos los valores son puramente enteros, podemos usar Int64.
                # 'Int64' es el tipo entero de Pandas que soporta valores nulos (pd.NA).
                df_copy[col] = temp_series.astype('Int64')
                print(f"  Columna '{col}': Convertida de {original_dtype} a {df_copy[col].dtype} (todos los valores son enteros, sin NaNs, o NaNs coercidos fueron tratados).")

        except Exception as e:
            # Esto es una red de seguridad si algo inesperado ocurre durante la conversi√≥n
            print(f"  Advertencia: No se pudo convertir la columna '{col}' a num√©rica debido a un error inesperado: {e}. Se mantiene el tipo actual ({original_dtype}).")
            df_copy[col] = df[col] # Revertir a la original si hay un error cr√≠tico

    return df_copy

## Convertir expl√≠citamente None a NaN en todo el DataFrame
async def convert_null_data(df: pd.DataFrame ):
  
    val = df.replace({None: np.nan}, inplace=True)
    return val

async def convert_null_data_with_value(df: pd.DataFrame, value: int | float, columns: list[Column] ):

    # columnas filtradas
    col_names = [col.name for col in columns]
    df_filtered = df[col_names]


    # Identificar columnas num√©ricas y categ√≥ricas Dataset con columnas vacias eliminadas
    numerical_cols = df_filtered.select_dtypes(include=np.number).columns
    categorical_cols = df_filtered.select_dtypes(include='object').columns

    numerical_imputer_zero = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value=value))
    ])
    #TODO esto hay que definir como par√°metro, no como valor fijo
    categorical_imputer_none = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing'))
    ])

    preprocessor_minimal_expressive = ColumnTransformer(
    transformers=[
        ('num_imp', numerical_imputer_zero, numerical_cols),
        ('cat_imp', categorical_imputer_none, categorical_cols) # Usar las columnas filtradas
    ],
    remainder='passthrough'
)
    df_transformado = fit_transform_with_column_names(preprocessor_minimal_expressive, df)
    return df_transformado

async def drop_rows_by_missing_threshold(
    df: pd.DataFrame,
    threshold_percentage: float,  # porcentaje de columnas con NaN para eliminar la fila (0-100)
    columns: list  # lista de columnas a evaluar
) -> pd.DataFrame:
    """
    Elimina filas si el porcentaje de valores faltantes en las columnas especificadas
    supera el umbral threshold_percentage. Las dem√°s filas quedan intactas.

    Args:
        df (pd.DataFrame): DataFrame original
        threshold_percentage (float): porcentaje (0-100) de columnas con NaN para eliminar fila
        columns (list): columnas a evaluar (lista de Column o str)

    Returns:
        pd.DataFrame: DataFrame resultante, mismo √≠ndice que el original
    """

    # Obtener nombres de columnas si recibimos objetos tipo Column
    col_names = [col.name if hasattr(col, 'name') else col for col in columns]

    # Filtramos solo las columnas que realmente existen en el DataFrame
    col_names = [col for col in col_names if col in df.columns]

    if not col_names:
        # Si no hay columnas v√°lidas, devolvemos el df original
        return df.copy()

    # N√∫mero de columnas a considerar
    total_cols = len(col_names)

    # Umbral absoluto: cu√°ntos NaN equivalen al porcentaje dado
    threshold_count = int(np.floor((threshold_percentage / 100) * total_cols))

    # Boolean mask: True si fila cumple con superar el umbral de NaN
    mask = df[col_names].isna().sum(axis=1) > threshold_count

    # Eliminamos filas que superan el umbral
    df_result = df.loc[~mask].copy()

    return df_result

# Eliminar valores duplicados
async def show_duplicates(df: pd.DataFrame):

    print("\nüîç Valores Duplicados Antes de Eliminar:")
    duplicates= df[df.duplicated(keep=False)] 
    return duplicates if not duplicates.empty else "No hay valores duplicados."

async def remove_duplicates(df: pd.DataFrame):
    initial_count = len(df)
    dataframe_rem = df.drop_duplicates(inplace=True)
    final_count = len(df)
    print(f"/n‚úÖ Valores Duplicados Eliminados: {initial_count - final_count} filas eliminadas.")

    return dataframe_rem

    # return dataframe_rem



async def identify_number_columns(df: pd.DataFrame):
    numeric_columns = df.select_dtypes(include=["number"]).columns
    if numeric_columns.empty:
        print("No hay columnas num√©ricas en el DataFrame.")
        return []

    return  numeric_columns.tolist()

async def identify_categorical_columns(df: pd.DataFrame):
    categorical_columns = df.select_dtypes(exclude=["number"]).columns
    if categorical_columns.empty:
        print("No hay columnas categ√≥ricas en el DataFrame.")
        return []

    return categorical_columns.tolist()

# Metodos de Imputacion de datos faltantes


#Imputacion por media aritmetica

async def aritmetic_mean_imputation(df: pd.DataFrame, columns: list[str]):

    # especifico para columnas numericas
    # columnas_numericas = identify_number_columns(df=df)


    imputer_numerico = SimpleImputer(strategy="mean")
    print("\nüîπ Usando imputaci√≥n con MEDIA.\n")

    df[columns] = imputer_numerico.fit_transform(df[columns])

    return df


async def arithmetic_mean_imputation_with_specification(df: pd.DataFrame, columns: list[str]) -> pd.DataFrame:
    """
    Imputa los valores NaN de las columnas num√©ricas especificadas usando la media.
    Solo aplica imputaci√≥n a columnas que realmente son num√©ricas.
    
    Args:
        df (pd.DataFrame): DataFrame sobre el que se trabaja
        columns (list[str]): columnas a evaluar
    
    Returns:
        pd.DataFrame: DataFrame con las columnas num√©ricas imputadas, mismo √≠ndice y nombres de columnas intactos
    """

    # Filtramos columnas que existen en el DataFrame
    col_names = [col for col in columns if col in df.columns]

    if not col_names:
        return df  # No hay columnas v√°lidas

    # Filtramos solo las columnas num√©ricas
    numerical_cols = df[col_names].select_dtypes(include=np.number).columns

    if len(numerical_cols) == 0:
        return df  # No hay columnas num√©ricas para imputar

    # Imputador por media
    imputer = SimpleImputer(strategy="mean")

    # Aplicamos imputaci√≥n solo a las columnas num√©ricas seleccionadas
    df[numerical_cols] = imputer.fit_transform(df[numerical_cols])

    return df


async def knn_imputation(df: pd.DataFrame, columns: list[str]):

    # especifico para valores numericos

    imputer_numerico = KNNImputer(n_neighbors=2)
    print("\nüîπ Usando imputaci√≥n con KNN-Imputer.\n")

    df[columns] = imputer_numerico.fit_transform(df[columns])
    return df


async def knn_imputation_with_specifications(df: pd.DataFrame, columns: list[str], n_neighbors: int = 5) -> pd.DataFrame:
    """
    Imputa valores NaN en columnas num√©ricas usando KNNImputer.
    
    Args:
        df (pd.DataFrame): DataFrame sobre el que se trabaja
        columns (list[str]): columnas a evaluar
        n_neighbors (int): n√∫mero de vecinos para KNN
    
    Returns:
        pd.DataFrame: DataFrame con columnas num√©ricas imputadas, mismo √≠ndice y nombres de columnas intactos
    """

    # Filtrar columnas que existen en el DataFrame
    col_names = [col for col in columns if col in df.columns]

    if not col_names:
        return df  # No hay columnas v√°lidas

    # Seleccionar solo columnas num√©ricas
    numerical_cols = df[col_names].select_dtypes(include=np.number).columns

    if len(numerical_cols) == 0:
        return df  # No hay columnas num√©ricas para imputar

    # Crear el imputador KNN
    imputer = KNNImputer(n_neighbors=n_neighbors)

    # Aplicar imputaci√≥n solo a las columnas num√©ricas seleccionadas
    df[numerical_cols] = imputer.fit_transform(df[numerical_cols])

    return df

async def moda_imputation(df: pd.DataFrame, columns: list[str]):
    # Aplicar imputaci√≥n a valores categ√≥ricos con moda (valor m√°s frecuente)
    imputer_categorico = SimpleImputer(strategy="most_frequent")
    df[columns] = imputer_categorico.fit_transform(df[columns])

    return df

async def mode_imputation_with_specifications(df: pd.DataFrame, columns: list[str]) -> pd.DataFrame:
    """
    Imputa los valores NaN de columnas categ√≥ricas usando la moda (valor m√°s frecuente).
    Solo se aplica a columnas de tipo object o categ√≥ricas.
    
    Args:
        df (pd.DataFrame): DataFrame sobre el que se trabaja
        columns (list[str]): columnas a evaluar
    
    Returns:
        pd.DataFrame: DataFrame con las columnas categ√≥ricas imputadas, mismo √≠ndice y nombres de columnas intactos
    """

    # Filtramos columnas que existen en el DataFrame
    col_names = [col for col in columns if col in df.columns]

    if not col_names:
        return df  # No hay columnas v√°lidas

    # Filtrar solo columnas categ√≥ricas
    categorical_cols = df[col_names].select_dtypes(include=['object', 'category']).columns

    if len(categorical_cols) == 0:
        return df  # No hay columnas categ√≥ricas para imputar

    # Imputador por moda
    imputer = SimpleImputer(strategy='most_frequent')

    # Aplicar imputaci√≥n solo a columnas categ√≥ricas
    df[categorical_cols] = imputer.fit_transform(df[categorical_cols])

    return df

async def saveDataFrame(df: pd.DataFrame, url: str, encoding: str):
    # df.to_csv()
    try:
        file_path = Path(url)

        df.to_csv(file_path, index=False, encoding=encoding)
        return True
    except Exception as e:
        print("Error al guardar CSV", e)
        return False


async def remove_empty_columns(df: pd.DataFrame) -> pd.DataFrame:

    if not isinstance(df, pd.DataFrame):
        raise TypeError("La entrada debe ser un DataFrame de Pandas.")

    # Identificar columnas donde TODOS los valores son NaN/null
    # df.isnull() devuelve un DataFrame booleano (True si es NaN, False si no)
    # .all() aplicado a un DataFrame booleano, por defecto, comprueba si TODAS
    # las entradas en cada columna son True (es decir, todas son NaN).
    # [df.isnull().all()] obtiene una Serie booleana donde el √≠ndice son los
    # nombres de las columnas y el valor es True si la columna est√° completamente vac√≠a.
    
    # df.columns[df.isnull().all()] te da los nombres de las columnas que cumplen esta condici√≥n.
    columns_to_drop = df.columns[df.isnull().all()].tolist()

    if columns_to_drop:
        print(f"Detectadas y eliminando columnas completamente vac√≠as: {columns_to_drop}")
        # df.drop() elimina las columnas especificadas.
        # axis=1 indica que queremos eliminar columnas (axis=0 es para filas).
        df_cleaned = df.drop(columns=columns_to_drop)
    else:
        print("No se encontraron columnas completamente vac√≠as para eliminar.")
        df_cleaned = df.copy() # Devolvemos una copia si no hay cambios para evitar SettingWithCopyWarning

    return df_cleaned










